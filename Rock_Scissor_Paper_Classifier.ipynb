{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "subject-enclosure",
   "metadata": {
    "id": "BK5Bp8_Xd9L9"
   },
   "source": [
    "# LMS Exploration | 1. Rock_Scissor_Paper Classifier\n",
    "---\n",
    "**[Introduce]** \n",
    "- 가위, 바위, 보 이미지 분류기\n",
    "- TensorFlow의 표준 API인 tf.keras의 Sequential APi를 이용하여 LeNet 을 바탕으로 딥러닝 네트워크를 설계한다.\n",
    "\n",
    "\n",
    "- Image Classifier of rock, scissor, paper\n",
    "- Design DeepLearning Network using LeNet\n",
    "\n",
    "\n",
    "**[dataset]** \n",
    "- 10명 이상의 다양한 손가락 이미지를 사용하여 가위, 바위, 보 각각 약 1400개의 data를 이용하여 훈련했으며, train dataset에 포함되지 않은 약 300 개의 test data로 테스트 했다.\n",
    "\n",
    "- 가위, 바위, 보 3개의 class 각각 약 1400개의 train data (총 4290 개)\n",
    "- 가위, 바위, 보 3개의 class 각각 약 100개의 test data (총 300 개)\n",
    "\n",
    "\n",
    "**[HyperParameter]** \n",
    "- 최적의 HyperParameter를 구하기 위해 검증 함수를 사용했다.\n",
    "\n",
    "\n",
    "**[Preparation]** \n",
    "- mkdir -p : 디렉토리 만들기 (make directory)\n",
    "- unzip : 이미지 압축 해제 (unzip zip files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-format",
   "metadata": {
    "id": "uR17Y1xdOvVQ"
   },
   "source": [
    "## 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-demographic",
   "metadata": {
    "id": "4V3voQMzO71R"
   },
   "source": [
    "- make directory (아래 폴더구조 참고)\n",
    "- unzip zip files\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**rock_scissor_paper**\n",
    "\n",
    "     #- train dataset\n",
    "     -rock\n",
    "     -scissor\n",
    "     -paper\n",
    "     -test\n",
    "         #- test dataset\n",
    "         -rock\n",
    "         -scissor\n",
    "         -paper\n",
    "         \n",
    "--- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-garbage",
   "metadata": {
    "id": "GgA9_rdvP0cN"
   },
   "source": [
    "## 2. 라이브러리 불러오기 | import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adjusted-excitement",
   "metadata": {
    "id": "hispanic-soundtrack"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-holocaust",
   "metadata": {
    "id": "HtFefa6sQBoT"
   },
   "source": [
    "## 3. 이미지 크기 변환하기 | resize images\n",
    "244x244 크기의 이미지를 28x28 크기로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "circular-explosion",
   "metadata": {
    "id": "naked-logging"
   },
   "outputs": [],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dynamic-metallic",
   "metadata": {
    "id": "ongoing-toilet",
    "outputId": "e589e69b-79eb-4732-9451-04b69ef865ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530  images to be resized.\n",
      "1530  images resized.\n",
      "1536  images to be resized.\n",
      "1536  images resized.\n",
      "1528  images to be resized.\n",
      "1528  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n"
     ]
    }
   ],
   "source": [
    "dir = [\"scissor\", \"rock\", \"paper\", \"test/rock\", \"test/scissor\", \"test/paper\"]\n",
    "\n",
    "for i in dir:\n",
    "    image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/\"+i\n",
    "    resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-morning",
   "metadata": {
    "id": "60ICUUfwQypz"
   },
   "source": [
    "## 4. 훈련 및 테스트 데이터 불러오기 | load train & test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "broadband-arena",
   "metadata": {
    "id": "current-water"
   },
   "outputs": [],
   "source": [
    "def load_data(img_path, number_of_data):\n",
    "    #- 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #- 이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    #- 데이터 영역에 이미지 행렬 복사\n",
    "        labels[idx]=0   \n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=1  \n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=2  \n",
    "        idx=idx+1\n",
    "\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "raised-fight",
   "metadata": {
    "id": "labeled-amino",
    "outputId": "1ad20cfa-b9be-4fa6-df5b-2d4dfd3974f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 4601 입니다.\n",
      "테스트데이터(x_test)의 이미지 개수는 306 입니다.\n"
     ]
    }
   ],
   "source": [
    "def number_of_data(a):\n",
    "    dir = [\"scissor\", \"rock\", \"paper\"]\n",
    "    number=0\n",
    "    if a == 'train':\n",
    "        for i in dir:\n",
    "            image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/\"+i\n",
    "            number += len(os.listdir(image_dir_path))\n",
    "        print(\"학습데이터(x_train)의 이미지 개수는\", number,\"입니다.\")\n",
    "    if a == 'test':\n",
    "        for i in dir:\n",
    "            image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/\"+i\n",
    "            number += len(os.listdir(image_dir_path))\n",
    "        print(\"테스트데이터(x_test)의 이미지 개수는\", number,\"입니다.\")\n",
    "    return number\n",
    "\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "x_train, y_train=load_data(image_dir_path, number_of_data('train'))\n",
    "\n",
    "\n",
    "image_dir_path = image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "x_test, y_test= load_data(image_dir_path, number_of_data('test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-possibility",
   "metadata": {
    "id": "RrUapX0hXMx3"
   },
   "source": [
    "## 5. 데이터 정규화 | normalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "geographic-wagon",
   "metadata": {
    "id": "xlej3cY4XLek"
   },
   "outputs": [],
   "source": [
    "x_train_norm = x_train/255.0\n",
    "x_test_norm = x_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-vatican",
   "metadata": {
    "id": "IiuY1udLTlqM"
   },
   "source": [
    "## 6. 하이퍼파라미터 검증 | evaluate HyperParameter\n",
    "다양한 하이퍼파라미터 조합을 검증함으로써 최적의 test accuracy 값을 도출해낸다.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-tennessee",
   "metadata": {},
   "source": [
    "**[Best Hyperparameter for this model]**\n",
    "    \n",
    "channel_1 : 128   \n",
    "channel_2 : 256    \n",
    "dense : 64       \n",
    "best_test_accuracy: 0.8627451062202454  \n",
    "\n",
    "\n",
    "(아래 코드의 실행 크기가 매우 크기 때문에, 최종 결과만 올립니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-recommendation",
   "metadata": {
    "id": "9jhrQjaXY-ia"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "n_train_epoch=10\n",
    "\n",
    "def get_model(n_channel_1, n_channel_2, n_dense):\n",
    "    for channel_1, channel_2, dense in product(n_channel_1, n_channel_2, n_dense):\n",
    "        model=keras.models.Sequential()\n",
    "        model.add(keras.layers.Conv2D(channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "        model.add(keras.layers.MaxPool2D(2,2))\n",
    "        model.add(keras.layers.Conv2D(channel_2, (3,3), activation='relu'))\n",
    "        model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(dense, activation='relu'))\n",
    "        model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                     loss='sparse_categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "        yield model, [channel_1, channel_2, dense]\n",
    "\n",
    "n_channel_1 = [16, 32, 64, 128]\n",
    "n_channel_2 = [32, 64, 128, 256]\n",
    "n_dense = [32, 64, 128, 256]\n",
    "\n",
    "best_test_acc = 0\n",
    "best_args = []\n",
    "\n",
    "for model, args in get_model(n_channel_1, n_channel_2, n_dense):\n",
    "    model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "    print(f\"test_loss: {test_loss} \")\n",
    "    if test_accuracy > best_test_acc:\n",
    "        best_test_acc = test_accuracy\n",
    "        best_args = args\n",
    "        print(\"BEST!!!\")\n",
    "    print(f\"channel_1 : {args[0]} channel_2 : {args[1]} dense : {args[2]} test_accuracy: {test_accuracy}\\n\\n\")\n",
    "\n",
    "\n",
    "print(f\"<Best Hyperparameter for this model> \\nchannel_1 : {best_args[0]}\\nchannel_2 : {best_args[1]}\\ndense : {best_args[2]}\\nbest_test_accuracy: {best_test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-killer",
   "metadata": {
    "id": "NOOFEjnySW5F"
   },
   "source": [
    "## 7. 딥러닝 네트워크 설계, 학습, 테스트 | Design, Train, Test DeepLearning Network "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-catalog",
   "metadata": {},
   "source": [
    "- Lenet 바탕의 DeepLearning Network\n",
    "- fit() : 학습\n",
    "- evaluate() : 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fresh-remains",
   "metadata": {
    "id": "higher-black",
    "outputId": "387a0556-19c6-4129-8354-3e2e3a93a3f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_128 (Conv2D)          (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_128 (MaxPoolin (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_129 (Conv2D)          (None, 11, 11, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_129 (MaxPoolin (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_64 (Flatten)         (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 64)                204864    \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 242,947\n",
      "Trainable params: 242,947\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 1.0795 - accuracy: 0.3885\n",
      "Epoch 2/10\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.6798\n",
      "Epoch 3/10\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.4093 - accuracy: 0.8486\n",
      "Epoch 4/10\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.8938\n",
      "Epoch 5/10\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.9462\n",
      "Epoch 6/10\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1503 - accuracy: 0.9565\n",
      "Epoch 7/10\n",
      "144/144 [==============================] - 1s 3ms/step - loss: 0.0846 - accuracy: 0.9797\n",
      "Epoch 8/10\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.0467 - accuracy: 0.9903\n",
      "Epoch 9/10\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9918\n",
      "Epoch 10/10\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9904\n",
      "10/10 - 0s - loss: 1.3898 - accuracy: 0.8105\n",
      "test_loss: 1.3897985219955444 \n",
      "test_accuracy: 0.8104575276374817\n"
     ]
    }
   ],
   "source": [
    "#- 딥러닝네트워크 설계\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#- 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=10)\n",
    "\n",
    "#- 테스트\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-colombia",
   "metadata": {},
   "source": [
    "## 8. 프로젝트 정리 | Summary\n",
    "---\n",
    "\n",
    "### 8-1. 최종결과\n",
    "\n",
    "**train dataset (개수, 다양성)** : 4601개, 10명의 dataset을 활용했으며 각 클래스별 균등한 개수의 데이터를 할당했다. \n",
    "\n",
    "**test dataset (개수, 다양성)** : 306개, 1명의 dataset을 활용했으며 각 클래스별 균등한 개수의 데이터를 할당했다. \n",
    "\n",
    "**channel1, channel2, dense** = 128 , 256 , 64\n",
    "\n",
    "**test_loss, test_accuracy** = 1.0453828573226929 , 0.8627451062202454\n",
    "\n",
    "\n",
    "### 8-2. 과정\n",
    "\n",
    "**첫번째 시도**에서, 본인의 손가락 이미지 데이터 300개로 훈련시키고, 다른 한 명의 손가락 이미지 300개로 테스트했다. 그 결과, accuracy 가 1.0에 수렴했다. 원인분석 결과, 데이터로드 중 실수로 테스트 이미지에 본인의 이미지가 다수 들어있어 과적합이 발생했다.\n",
    "\n",
    "**두번째 시도**에서, 10명의 이미지 데이터 총 4000개로 훈련시키고, 훈련데이터와 중복되지 않는 다른 한 명의 손가락 이미지 300개로 테스트했다. 그 결과, accuracy가 0.6을 겨우 넘겼다. 원인분석 결과 하이퍼파라미터의 조절이 필요하다고 생각되어, 검증함수를 도입했고, 다양성에 주의를 기울여 약 600개의 훈련 데이터를 추가했다.\n",
    "\n",
    "**세번째 시도**에서, 11명의 이미지 데이터 총 4600개로 훈련시키고, 훈련데이터와 중복되지 않는 다른 한 명의 손가락 이미지 300개로 테스트했다. 그 결과 test accuracy 약 0.86 의 결과를 얻었다. \n",
    "\n",
    "### 8-3. 자가평가 \n",
    "\n",
    "DeepLearning Model의 학습에서 Model도 중요하지만 무엇보다도 **dataset의 질**이 중요하다는 것을 느꼈다. 지도학습 분류모델에서, overfitting을 방지하기 위해서는 각 클래스의 데이터가 균형잡혀야 하며, 다양한 데이터가 필요하다는 것을 배웠다. 앞으로 딥러닝모델을 학습시킬 때 있어서 데이터의 정제에 특별히 주의를 기울여야겠다.     \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "E1_Rock_Scissor_Paper_Classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
